{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we will move 'A' within a 4x4 map till it reaches the start and end terminal with the help of\n",
    "dynamic programming and reinforcement learning.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from random import random, choice\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Example: 4 x 4\n",
    "#    -----------------\n",
    "#    | 0 | 1 | 2 | 3 |\n",
    "#    -----------------\n",
    "#    | 4 | 5 | 6 | 7 |\n",
    "#    -----------------\n",
    "#    | A | 9 | 10| 11|\n",
    "#    -----------------\n",
    "#    | 12| 13| 14| 15|\n",
    "#    -----------------\n",
    "# We are defining a 4x4 map with terminals at 0 and 15\n",
    "dimensions = (r,c)=(4,4)\n",
    "MAP_RANGE = r*c\n",
    "positions = range(MAP_RANGE) #Include all values except initial and final (0 and 16)\n",
    "TERMINALS = {0,15}\n",
    "open_pos = set(positions)- TERMINALS #creates a set of open positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_policy():\n",
    "    #Random Policy - assign each position with a probability\n",
    "    #Every position is given the probability of 0.25 except the terminals which have the probaility 0\n",
    "    return{i: {d: (0 if i in TERMINALS else 0.25) for d in \"NEWS\"} for i in positions}\n",
    "\n",
    "#print(create_random_policy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(i, step):\n",
    "    #here i is current position and c is number of columns\n",
    "    if step =='N' and i -c >=0: \n",
    "        i -=c\n",
    "    elif step =='E' and i % c != c-1:\n",
    "        i += 1\n",
    "    elif step == 'W' and i%c != 0:\n",
    "        i -=1\n",
    "    elif step == 'S' and i+c <MAP_RANGE:\n",
    "        i +=c\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position_change_map():\n",
    "    #Position Change Map: returns how the agent will move within the map\n",
    "    #The movement will not exceed borders and the agent will remian in place if asked to do so\n",
    "    return {i: {d: in_range(i, d) for d in \"NEWS\"} for i in positions}\n",
    "\n",
    "#print(create_position_change_map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Board/MAP\n",
    "def print_board(agnt_pos):\n",
    "    hline = \"-\" * (4 * c + 1) #horizontal line\n",
    "    board = [hline] #initialize board\n",
    "    for i in range(0, MAP_RANGE, c):\n",
    "        board.append(''.join((\"| \" + ('A' if c == agnt_pos else 'X'\n",
    "                                      if c in TERMINALS else ' ') + ' ')\n",
    "                             for c in positions[i:i+c]) + '|')\n",
    "        board.append(hline)\n",
    "    print('\\n'.join(board), \"\\n\")\n",
    "    \n",
    "#print_board(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(policy, start_pos=None, verbose=False):\n",
    "    # Choose initial position\n",
    "    agent_pos = choice(positions) if start_pos is None else start_pos #passes a random starting point if not specified\n",
    "    state_to_state_prime = create_position_change_map() \n",
    "\n",
    "    step_no = 0\n",
    "    if verbose:\n",
    "        print(f\"Step: {step_no} Position: {agent_pos} Action: Initial\")\n",
    "        print_board(agent_pos)\n",
    "    # While agent is not at terminal postitions, let it move.\n",
    "    while agent_pos not in TERMINALS:\n",
    "        next_move = random()\n",
    "        lower_bound = 0\n",
    "        for action, chance in policy[agent_pos].items():\n",
    "            if lower_bound <= next_move < lower_bound + chance:\n",
    "                agent_pos = state_to_state_prime[agent_pos][action]\n",
    "                break\n",
    "            lower_bound += chance\n",
    "        step_no += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Step: {step_no} Position: {agent_pos} Action: {action}\")\n",
    "            print_board(agent_pos)\n",
    "\n",
    "    return step_no   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Policy\n",
      "-Average steps to finish: 16.155\n"
     ]
    }
   ],
   "source": [
    "policy = create_random_policy()\n",
    "#agent(policy, None, verbose=True) #uncomment it to see the movement of agent within the map till it reaches a terminal\n",
    "\n",
    "data = [agent(policy) for i in range(1000)] \n",
    "#runs the agent function with random starting values for 1000 times and stores number of steps required in form of a list\n",
    "print(f\"Random Policy\\n-Average steps to finish: {sum(data) / len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probability_map():\n",
    "    pos_map = create_position_change_map()\n",
    "    return {(pr, stt, mv): 0 if pr != pos_map[stt][mv] else 1\n",
    "            for stt in positions for mv in 'NEWS' for pr in positions}\n",
    "    #returns list of all possible movements\n",
    "    #E.g. (6,2,'S'):1 states that movement of 2 towards 6 in the south direction is a valid move\n",
    "\n",
    "#create_probability_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_greedy_policy(v_s):\n",
    "    pos_map = create_position_change_map()\n",
    "    policy = {}\n",
    "\n",
    "    for stt in positions:\n",
    "        state_values = {d: v_s[pos_map[stt][d]] for d in 'NEWS'}\n",
    "        max_st_val = max(state_values.values())\n",
    "        max_actions = [k for k, v in state_values.items() if v == max_st_val]\n",
    "        policy[stt] = {d: 1 / len(max_actions) if d in max_actions and\n",
    "                       stt not in TERMINALS else 0.0 for d in 'NEWS'}\n",
    "    return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_policy_evaluation(policy, theta=0.01, discount=0.5):\n",
    "    v_s = {i: 0 for i in positions}\n",
    "    prob_map = create_probability_map()\n",
    "\n",
    "    delta = 100\n",
    "    while delta >= theta:\n",
    "        new_vs = {stt: round(sum(policy[stt][mv]\n",
    "                                 * sum(prob_map[(pr, stt, mv)] *\n",
    "                                       (-1 + discount * v_s[pr])\n",
    "                                       for pr in positions)\n",
    "                                 for mv in \"NEWS\"), 4) for stt in positions}\n",
    "        delta = max(abs(v_s[stt] - new_vs[stt]) for stt in positions)\n",
    "        v_s = deepcopy(new_vs)\n",
    "    return v_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: -1.6914, 2: -1.944, 3: -1.9773, 4: -1.6914, 5: -1.9107, 6: -1.961, 7: -1.944, 8: -1.944, 9: -1.961, 10: -1.9107, 11: -1.6914, 12: -1.9773, 13: -1.944, 14: -1.6914, 15: 0.0}\n",
      "Greedy Policy V1\n",
      "Average steps to finish: 1.763\n"
     ]
    }
   ],
   "source": [
    "v_s = iterative_policy_evaluation(create_random_policy())\n",
    "policy = create_greedy_policy(v_s)\n",
    "print(v_s)\n",
    "\n",
    "data = [agent(policy) for i in range(1000)]\n",
    "\n",
    "print(f\"Greedy Policy V1\\nAverage steps to finish: {sum(data) / len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: -1.0, 2: -1.5, 3: -1.75, 4: -1.0, 5: -1.5, 6: -1.75, 7: -1.5, 8: -1.5, 9: -1.75, 10: -1.5, 11: -1.0, 12: -1.75, 13: -1.5, 14: -1.0, 15: 0.0}\n",
      "Greedy Policy V2\n",
      "Average steps to finish: 1.793\n"
     ]
    }
   ],
   "source": [
    "v_s = iterative_policy_evaluation(policy)\n",
    "policy = create_greedy_policy(v_s)\n",
    "print(v_s)\n",
    "\n",
    "data = [agent(policy) for i in range(1000)]\n",
    "print(f\"Greedy Policy V2\\nAverage steps to finish: {sum(data) / len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Position: 1 Action: Initial\n",
      "-----------------\n",
      "| X | A |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   | X |\n",
      "----------------- \n",
      "\n",
      "Step: 1 Position: 0 Action: W\n",
      "-----------------\n",
      "| A |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   | X |\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(policy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -1.9922, 1: -1.9922, 2: -1.9922, 3: -1.9922, 4: -1.9922, 5: -1.9922, 6: -1.9922, 7: -1.9922, 8: -1.9922, 9: -1.9922, 10: -1.9922, 11: -1.9922, 12: -1.9922, 13: -1.9922, 14: -1.9922, 15: -1.9922}\n",
      "Greedy Policy with Value Iteration\n",
      "Average steps to finish: 16.485\n"
     ]
    }
   ],
   "source": [
    "def value_iteration(v_s=None, theta=0.01, discount=0.5):\n",
    "    v_s = {i: 0 for i in positions} if v_s is None else v_s\n",
    "    prob_map = create_probability_map()\n",
    "\n",
    "    delta = 100\n",
    "    while delta >= theta:\n",
    "        new_vs = {stt: round(max(sum(prob_map[(pr, stt, mv)]\n",
    "                                     * (-1 + discount * v_s[pr])\n",
    "                                     for pr in positions) for mv in \"NEWS\"), 4)\n",
    "                  for stt in positions}\n",
    "        delta = max(abs(v_s[stt] - new_vs[stt]) for stt in positions)\n",
    "        v_s = deepcopy(new_vs)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "v_s = value_iteration()\n",
    "policy = create_greedy_policy(v_s)\n",
    "\n",
    "print(v_s)\n",
    "\n",
    "data = [agent(policy) for i in range(1000)]\n",
    "\n",
    "print(\"Greedy Policy with Value Iteration\\nAverage steps to finish:\",\n",
    "      f\"{sum(data) / len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Position: 8 Action: Initial\n",
      "-----------------\n",
      "| X |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "| A |   |   |   |\n",
      "-----------------\n",
      "|   |   |   | X |\n",
      "----------------- \n",
      "\n",
      "Step: 1 Position: 4 Action: N\n",
      "-----------------\n",
      "| X |   |   |   |\n",
      "-----------------\n",
      "| A |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   | X |\n",
      "----------------- \n",
      "\n",
      "Step: 2 Position: 0 Action: N\n",
      "-----------------\n",
      "| A |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   |   |\n",
      "-----------------\n",
      "|   |   |   | X |\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(create_greedy_policy(value_iteration(v_s)), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
